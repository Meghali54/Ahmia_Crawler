# ğŸ•¸ï¸ Ahmia Onion Link Crawler

A Python-based crawler that scrapes `.onion` links from [Ahmia.fi](https://ahmia.fi/onions/), checks for duplicates, and stores new links into a MongoDB Atlas database â€” all automated as a scheduled cron job on Render.com.

---

## ğŸš€ Features

- âœ… Automatically fetches `.onion` links from [Ahmia.fi](https://ahmia.fi/onions/)
- âœ… Stores only new/unseen links to avoid duplicates
- âœ… Saves metadata: source, crawled timestamp
- âœ… Hosted on [Render](https://render.com) with 24h daily cron job
- âœ… Runs independently â€” no local machine required

---

## ğŸ—ƒï¸ Data Schema

Each document in MongoDB looks like:

```json
{
  "onionLink": "http://exampleonionlink.onion",
  "source": "Ahmia",
  "crawledTimestamp": "2025-06-20T00:00:00Z"
}
